{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and read the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the dataset from hdf5 file and show the data struction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from scripts.convert_to_rlds import extract_step_data,process_step,create_episode\n",
    "\n",
    "def get_all_hdf5_files(directory):\n",
    "    \"\"\"\n",
    "    Get all HDF5 files in a directory and its subdirectories.\n",
    "    \"\"\"\n",
    "    hdf5_files = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.hdf5'):\n",
    "                hdf5_files.append(os.path.join(root, file))\n",
    "    return hdf5_files\n",
    "\n",
    "def print_structure(group, indent=0):\n",
    "    \"\"\"\n",
    "    Print the hierarchical structure of an HDF5 group.\n",
    "    \"\"\"\n",
    "    for key in group.keys():\n",
    "        item = group[key]\n",
    "        print(\" \" * indent + key)\n",
    "        if isinstance(item, h5py.Group):\n",
    "            print_structure(item, indent + 4)\n",
    "        elif isinstance(item, h5py.Dataset):\n",
    "            print(\" \" * indent, item.shape, item.dtype)\n",
    "            if key == \"entities\" or key == \"target_entity\" or key == \"instruction\":\n",
    "                decoded = [x.decode('utf-8') for x in item]\n",
    "                print(\" \" * indent, decoded)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/data/310_jiarui/VLABench/media/select_fruit_4_fixed_pos/select_fruit/data_286.hdf5', '/mnt/data/310_jiarui/VLABench/media/select_fruit_4_fixed_pos/select_fruit/data_144.hdf5', '/mnt/data/310_jiarui/VLABench/media/select_fruit_4_fixed_pos/select_fruit/data_607.hdf5']\n"
     ]
    }
   ],
   "source": [
    "dataset_root = \"/mnt/data/310_jiarui/VLABench/media/select_fruit_4_fixed_pos/select_fruit\" \n",
    "hdf5_files = get_all_hdf5_files(dataset_root)\n",
    "print(hdf5_files[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2025-04-16 03:00:18', '2025-04-16 03:00:59', '2025-04-16 11:23:33', '2025-04-16 11:25:24', '2025-04-16 23:01:07', '2025-04-17 07:58:09', '2025-04-17 17:08:07']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\ndata\\n    2025-03-29 02:23:07\\n        instruction\\n         (1,) |S34\\n         ['Put the banana into the plate_seen']\\n        meta_info\\n            entities\\n             (5,) |S10\\n             ['table', 'plate_seen', 'banana', 'orange', 'apple']\\n            episode_config\\n             () |S1697\\n            target_entity\\n             (1,) |S6\\n             ['banana']\\n        observation\\n            ee_state\\n             (157, 8) float32\\n            q_acceleration\\n             (157, 7, 1) float32\\n            q_state\\n             (157, 7, 1) float32\\n            q_velocity\\n             (157, 7, 1) float32\\n            rgb\\n             (157, 6, 480, 480, 3) uint8\\n            robot_mask\\n             (157, 6, 480, 480) float32\\n        trajectory\\n         (0,) float32\\n\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_file = random.choice(hdf5_files)\n",
    "with h5py.File(example_file, 'r') as f:\n",
    "    #print_structure(f)\n",
    "        # 打印 trajectory 信息\n",
    "    timestamp_keys = list(f[\"data\"].keys())\n",
    "    print(timestamp_keys)\n",
    "\n",
    "\n",
    "    # if \"trajectory\" in f[\"data\"][timestamp_key]:\n",
    "    #     traj_data = f[\"data\"][timestamp_key][\"trajectory\"][()]\n",
    "    #     print(f\"Shape: {traj_data.shape}\")\n",
    "    #     print(f\"\\nTrajectory dataset info:\")\n",
    "    #     print(traj_data[0])\n",
    "    #     print(traj_data[1])\n",
    "    #     print(traj_data[2])\n",
    "    #     print(f[\"data\"][timestamp_key][\"instruction\"][()])\n",
    "\"\"\"\n",
    "data\n",
    "    2025-03-29 03:31:29\n",
    "        observation\n",
    "            ee_state\n",
    "             (137, 8) float32\n",
    "            q_acceleration\n",
    "             (137, 7, 1) float32\n",
    "            q_state\n",
    "             (137, 7, 1) float32\n",
    "            q_velocity\n",
    "             (137, 7, 1) float32\n",
    "            rgb\n",
    "             (137, 6, 480, 480, 3) uint8\n",
    "            robot_mask\n",
    "             (137, 6, 480, 480) float32\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "data\n",
    "    2025-03-29 02:23:07\n",
    "        instruction\n",
    "         (1,) |S34\n",
    "         ['Put the banana into the plate_seen']\n",
    "        meta_info\n",
    "            entities\n",
    "             (5,) |S10\n",
    "             ['table', 'plate_seen', 'banana', 'orange', 'apple']\n",
    "            episode_config\n",
    "             () |S1697\n",
    "            target_entity\n",
    "             (1,) |S6\n",
    "             ['banana']\n",
    "        observation\n",
    "            ee_state\n",
    "             (157, 8) float32\n",
    "            q_acceleration\n",
    "             (157, 7, 1) float32\n",
    "            q_state\n",
    "             (157, 7, 1) float32\n",
    "            q_velocity\n",
    "             (157, 7, 1) float32\n",
    "            rgb\n",
    "             (157, 6, 480, 480, 3) uint8\n",
    "            robot_mask\n",
    "             (157, 6, 480, 480) float32\n",
    "        trajectory\n",
    "         (0,) float32\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing steps:   0%|          | 0/2 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/tyj/Documents/310_jiarui/VLABench/debug_dataset/episode_0.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m dataset_root \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/tyj/Documents/310_jiarui/VLABench/media/select_fruit/data_100.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m \n\u001b[1;32m      3\u001b[0m hdf5_files \u001b[38;5;241m=\u001b[39m get_all_hdf5_files(dataset_root)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mcreate_episode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43msave_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/310_jiarui/VLABench/scripts/convert_to_rlds.py:66\u001b[0m, in \u001b[0;36mcreate_episode\u001b[0;34m(file_path, save_dir, batch_size)\u001b[0m\n\u001b[1;32m     64\u001b[0m     save_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepisode_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mbatch_size\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39midx\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# if not os.path.exists(save_path):\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpisode saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     68\u001b[0m episodes \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# Clear the batch\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/vlabench/lib/python3.10/site-packages/numpy/lib/npyio.py:542\u001b[0m, in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    541\u001b[0m         file \u001b[38;5;241m=\u001b[39m file \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 542\u001b[0m     file_ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file_ctx \u001b[38;5;28;01mas\u001b[39;00m fid:\n\u001b[1;32m    545\u001b[0m     arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(arr)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/tyj/Documents/310_jiarui/VLABench/debug_dataset/episode_0.npy'"
     ]
    }
   ],
   "source": [
    "save_dir = \"/home/tyj/Documents/310_jiarui/VLABench/debug_dataset\"\n",
    "dataset_root = \"/home/tyj/Documents/310_jiarui/VLABench/media/select_fruit/data_100.hdf5\" \n",
    "hdf5_files = get_all_hdf5_files(dataset_root)\n",
    "create_episode(dataset_root,save_dir,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Convert to tf dataset (Optional)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlabench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
